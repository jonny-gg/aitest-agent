"""Celery Workeré…ç½®"""
from celery import Celery
from loguru import logger
import asyncio
from datetime import datetime

from app.config import get_settings
from app.database import AsyncSessionLocal, Task, TaskLog, CoverageReport, Project, TaskStatus
from app.agent.test_agent import TestGenerationAgent
from uuid import uuid4


settings = get_settings()

# åˆ›å»ºCeleryåº”ç”¨
celery_app = Celery(
    "aitest_worker",
    broker=settings.celery_broker_url,
    backend=settings.celery_result_backend
)

# Celeryé…ç½®
celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=settings.celery_task_time_limit,  # ä»ç¯å¢ƒå˜é‡è¯»å–è¶…æ—¶æ—¶é—´
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=50,
    worker_concurrency=settings.celery_worker_concurrency,  # ä»ç¯å¢ƒå˜é‡è¯»å–å¹¶å‘æ•°
)


@celery_app.task(bind=True, name="run_test_generation_task")
def run_test_generation_task(self, task_id: str):
    """
    æ‰§è¡Œæµ‹è¯•ç”Ÿæˆä»»åŠ¡
    
    Args:
        task_id: ä»»åŠ¡ID
    """
    logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_id}")
    
    # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡
    loop = asyncio.get_event_loop()
    result = loop.run_until_complete(_execute_task(task_id, self))
    
    return result


async def _execute_task(task_id: str, celery_task):
    """æ‰§è¡Œä»»åŠ¡çš„å¼‚æ­¥å‡½æ•°"""
    async with AsyncSessionLocal() as db:
        try:
            # è·å–ä»»åŠ¡ä¿¡æ¯
            from sqlalchemy import select
            
            result = await db.execute(
                select(Task).where(Task.id == task_id)
            )
            task = result.scalar_one_or_none()
            
            if not task:
                logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return {"error": "Task not found"}
            
            # è·å–é¡¹ç›®é…ç½®
            result = await db.execute(
                select(Project).where(Project.id == task.project_id)
            )
            project = result.scalar_one_or_none()
            
            if not project:
                logger.error(f"é¡¹ç›®ä¸å­˜åœ¨: {task.project_id}")
                return {"error": "Project not found"}
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = TaskStatus.CLONING
            task.started_at = datetime.utcnow()
            await db.commit()
            
            # åˆ›å»ºè¿›åº¦å›è°ƒ
            async def progress_callback(progress: int, status: str, message: str):
                # æ›´æ–°ä»»åŠ¡è¿›åº¦
                task.progress = progress
                task.status = TaskStatus[status] if status in TaskStatus.__members__ else task.status
                
                # æ·»åŠ æ—¥å¿—
                log = TaskLog(
                    id=str(uuid4()),
                    task_id=task_id,
                    level="INFO",
                    message=message
                )
                db.add(log)
                await db.commit()
                
                # æ›´æ–°Celeryä»»åŠ¡çŠ¶æ€
                celery_task.update_state(
                    state='PROGRESS',
                    meta={'progress': progress, 'status': status, 'message': message}
                )
            
            # æ‰§è¡Œæµ‹è¯•ç”Ÿæˆ
            agent = TestGenerationAgent()
            
            project_config = {
                'git_url': project.git_url,
                'git_branch': project.git_branch,
                'language': project.language.value,
                'test_framework': project.test_framework.value,
                'source_directory': project.source_directory,
                'test_directory': project.test_directory,
                'auto_commit': project.auto_commit,
                'create_pr': project.create_pr,
                'ai_provider': settings.ai_provider,
                'max_test_fix_retries': settings.max_test_fix_retries,
                'enable_auto_fix': settings.enable_auto_fix,
                'max_concurrent_generations': settings.max_concurrent_generations,
                'skip_existing_tests': settings.skip_existing_tests
            }
            
            result = await agent.execute(
                task.project_id,
                project_config,
                task_id,
                progress_callback
            )
            
            # æ›´æ–°ä»»åŠ¡ç»“æœ
            if result['success']:
                task.status = TaskStatus.COMPLETED
                task.commit_hash = result['commit_hash']
                task.generated_tests = result['test_files']
                task.total_tests = result['test_results'].get('total', 0)
                task.passed_tests = result['test_results'].get('passed_count', 0)
                task.failed_tests = result['test_results'].get('failed_count', 0)
                task.line_coverage = result['coverage'].get('line_coverage')
                task.branch_coverage = result['coverage'].get('branch_coverage')
                task.function_coverage = result['coverage'].get('function_coverage')
                task.coverage_data = result['coverage']
                task.completed_at = datetime.utcnow()
                
                # ä¿å­˜è¦†ç›–ç‡æŠ¥å‘Š
                if result['coverage']:
                    coverage_report = CoverageReport(
                        id=str(uuid4()),
                        task_id=task_id,
                        project_id=task.project_id,
                        total_lines=0,  # éœ€è¦ä»coverage_dataä¸­æå–
                        covered_lines=0,
                        line_coverage=result['coverage'].get('line_coverage', 0.0),
                        total_branches=0,
                        covered_branches=0,
                        branch_coverage=result['coverage'].get('branch_coverage', 0.0),
                        total_functions=0,
                        covered_functions=0,
                        function_coverage=result['coverage'].get('function_coverage', 0.0),
                        files_coverage=result['coverage'].get('files_coverage', {})
                    )
                    db.add(coverage_report)
                
                logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task_id}")
            else:
                task.status = TaskStatus.FAILED
                task.error_message = result.get('error')
                task.completed_at = datetime.utcnow()
                
                logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {task_id}")
            
            await db.commit()
            
            return {
                'task_id': task_id,
                'success': result['success'],
                'test_files': result['test_files'],
                'coverage': result['coverage']
            }
        
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
            
            # æ›´æ–°ä»»åŠ¡ä¸ºå¤±è´¥çŠ¶æ€
            task.status = TaskStatus.FAILED
            task.error_message = str(e)
            task.completed_at = datetime.utcnow()
            await db.commit()
            
            return {"error": str(e)}


@celery_app.task(name="cleanup_old_tasks")
def cleanup_old_tasks():
    """æ¸…ç†æ—§ä»»åŠ¡ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰"""
    logger.info("ğŸ§¹ æ¸…ç†æ—§ä»»åŠ¡...")
    # TODO: å®ç°æ¸…ç†é€»è¾‘
    return {"message": "Cleanup completed"}


# å®šæ—¶ä»»åŠ¡é…ç½®
celery_app.conf.beat_schedule = {
    'cleanup-every-day': {
        'task': 'cleanup_old_tasks',
        'schedule': 86400.0,  # æ¯å¤©æ‰§è¡Œä¸€æ¬¡
    },
}

